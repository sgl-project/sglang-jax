# FP8 weight-only quantization with MoE gate in full precision
# - MoE gate (router) is NOT quantized for numerical stability
# - All other layers: FP8 weights only, NO activation quantization
# - Reference: https://arxiv.org/pdf/2101.03961

quantization:
  qwix:
    rules:
      # All layers EXCEPT MoE gate, experts, and logits_processor - full W8A8
      # MoE gate: completely excluded (no weight, no activation quantization)
      # MoE experts unpermute: excluded from qwix
      # logits_processor: excluded for accuracy
      - module_path: '^(?!.*(mlp\.gate|mlp|logits_processor)).*$'
        weight_qtype: 'float8_e4m3fn'
        act_qtype: 'float8_e4m3fn'

  # MoE experts: FP8 weights only, NO activation quantization
  moe:
    weight_dtype: 'float8_e4m3fn'
    activation_dtype: 'float8_e4m3fn'
