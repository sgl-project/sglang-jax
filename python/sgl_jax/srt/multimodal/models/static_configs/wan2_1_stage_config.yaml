model_arch: Wan-AI/Wan2.1-T2V-1.3B-Diffusers
# how can we mapping model name to stage config yaml and impl class
stage_args:
 - stage_id: 0
   stage_sub_dir: text_encoder
   runtime:
     num_tpus: 2
     max_batch_size: 1
   scheduler: auto_regressive
   final_output: false
   scheduler_params: {}
   precompile_params: {"capture_hidden_mode": 2}
   model_class: UMT5EncoderModel

 - stage_id: 1
   stage_sub_dir: transformer
   runtime:
     num_tpus: 1
     max_batch_size: 1
   scheduler: diffusion
   scheduler_params: {}
   precompile_params: {"input_embedding": False, "deepstack_visual_embedding": False}
   model_class: WanTransformer3DModel
   final_output: false

 - stage_id: 2
   stage_sub_dir: vae
   runtime:
     num_tpus: 1
     max_batch_size: 1
   scheduler: vae
   scheduler_params: {}
   model_class: AutoencoderKLWan
     # a: b
   # args:
   #   engine_type: xxx, ar or diffusion
   #   model_stage: thinker
   #   model_arch: Qwen3OmniMoeForConditionalGeneration
   #   mem_fraction_static: 0.6
   #   trust_remote_code: true
   #   engine_output_type: latent  # Output hidden states for talker
   #   distributed_executor_backend: "mp"
   #   disable_radix_cache: true
   #   hf_config_name: thinker_config
   #   tensor_parallel_size: 2
   final_output: true
   # final_output_type: video
   # is_comprehension: true
   # default_sampling_params:
   #   temperature: 0.4
   #   top_p: 0.9
   #   top_k: 1
   #   max_tokens: 2048
   #   seed: 42
   #   detokenize: True
   #   repetition_penalty: 1.05
