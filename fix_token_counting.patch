"""Fix for token counting issue caused by KV head replication.

Apply this patch to python/sgl_jax/srt/managers/scheduler.py
"""

# In scheduler.py, modify the _get_token_info method:

def _get_token_info(self):
    available_size = self.token_to_kv_pool_allocator.available_size()
    evictable_size = self.tree_cache.evictable_size()
    num_used = self.max_total_num_tokens - (available_size + evictable_size)

    # FIX: Adjust for KV head replication when tp_size > num_kv_heads
    if self.tp_size > self.model_config.get_total_num_kv_heads():
        # Each unique KV head is replicated across multiple TP ranks
        # The token count should only reflect unique tokens, not replicated ones
        replication_factor = self.tp_size // self.model_config.get_total_num_kv_heads()
        num_used = num_used // replication_factor
        available_size = available_size // replication_factor
        evictable_size = evictable_size // replication_factor
        # Also adjust max_total_num_tokens for correct usage calculation
        adjusted_max = self.max_total_num_tokens // replication_factor
        token_usage = num_used / adjusted_max
    else:
        token_usage = num_used / self.max_total_num_tokens

    return num_used, token_usage, available_size, evictable_size

# Similarly, update _get_swa_token_info if using hybrid cache:

def _get_swa_token_info(self):
    full_available_size = self.token_to_kv_pool_allocator.full_available_size()
    full_evictable_size = self.tree_cache.full_evictable_size()
    swa_available_size = self.token_to_kv_pool_allocator.swa_available_size()
    swa_evictable_size = self.tree_cache.swa_evictable_size()
    full_num_used = self.full_tokens_per_layer - (full_available_size + full_evictable_size)
    swa_num_used = self.swa_tokens_per_layer - (swa_available_size + swa_evictable_size)

    # FIX: Adjust for KV head replication
    if self.tp_size > self.model_config.get_total_num_kv_heads():
        replication_factor = self.tp_size // self.model_config.get_total_num_kv_heads()
        full_num_used = full_num_used // replication_factor
        swa_num_used = swa_num_used // replication_factor
        full_available_size = full_available_size // replication_factor
        swa_available_size = swa_available_size // replication_factor
        full_evictable_size = full_evictable_size // replication_factor
        swa_evictable_size = swa_evictable_size // replication_factor
        adjusted_full_max = self.full_tokens_per_layer // replication_factor
        adjusted_swa_max = self.swa_tokens_per_layer // replication_factor
        full_token_usage = full_num_used / adjusted_full_max
        swa_token_usage = swa_num_used / adjusted_swa_max
    else:
        full_token_usage = full_num_used / self.full_tokens_per_layer
        swa_token_usage = swa_num_used / self.swa_tokens_per_layer

    return (
        full_num_used,
        swa_num_used,
        full_token_usage,
        swa_token_usage,
        full_available_size,
        swa_available_size,
        full_evictable_size,
        swa_evictable_size,
    )

# Note: You'll need to add a reference to model_config in Scheduler class
# Add in Scheduler.__init__:
#   self.model_config = self.tp_worker.model_config
