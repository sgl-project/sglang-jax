"""
ç§‘å­¦çš„ä¸‰é˜¶æ®µæµæ°´çº¿è®¾è®¡ï¼šDMA -> Preprocess -> Compute
"""

import time

import jax
import numpy as np
from utils import create_prefill_uniform_data

from sgl_jax.srt.layers.attention.flash_attn_kernel.flash_attention import (
    ragged_paged_attention,
)


def analyze_computation_breakdown():
    """åˆ†æè®¡ç®—çš„è¯¦ç»†æ„æˆï¼Œä¸ºæµæ°´çº¿è®¾è®¡æä¾›ä¾æ®"""

    # ä½¿ç”¨ç›¸åŒçš„æ•°æ®é…ç½®
    batch_size, seq_len, num_heads, head_dim = 2, 2048, 8, 128
    page_size = 128
    max_kv_cache_tokens_num = 120000

    q, k, v, _, page_indices, cu_q_lens, cu_kv_lens, num_seqs, seq_lens, _ = (
        create_prefill_uniform_data(
            batch_size,
            seq_len,
            seq_len,
            max_kv_cache_tokens_num,
            num_heads,
            head_dim,
            page_size=page_size,
        )
    )

    print("ğŸ”¬ åˆ†æFlash Attentionçš„è®¡ç®—æ„æˆ")
    print("ç›®æ ‡ï¼šè®¾è®¡ç§‘å­¦çš„ä¸‰é˜¶æ®µæµæ°´çº¿")

    # æ¨¡æ‹Ÿä¸åŒçš„æµæ°´çº¿æ·±åº¦
    configs = [
        ("å½“å‰åŒç¼“å†²", 2),
        ("ä¸‰é˜¶æ®µæµæ°´çº¿", 3),
        ("å››é˜¶æ®µæµæ°´çº¿", 4),
        ("æ·±åº¦æµæ°´çº¿", 6),
    ]

    results = {}
    optimal_kv_pages = 16
    optimal_q_block = 48

    for name, pipe_depth in configs:
        print(f"\n=== {name} (æ·±åº¦{pipe_depth}) ===")

        @jax.jit
        def pipeline_config():
            return ragged_paged_attention(
                q,
                k,
                v,
                page_indices,
                cu_q_lens,
                cu_kv_lens,
                num_seqs,
                seq_lens,
                sm_scale=head_dim**-0.5,
                num_kv_pages_per_block=optimal_kv_pages,
                num_queries_per_block=optimal_q_block,
                vmem_limit_bytes=32
                * 1024
                * 1024
                * pipe_depth,  # æ ¹æ®æµæ°´çº¿æ·±åº¦åˆ†é…VMEM
            )

        # é¢„çƒ­
        result = pipeline_config()
        jax.block_until_ready(result)

        # æµ‹è¯•
        times = []
        for i in range(5):
            start = time.perf_counter()
            result = pipeline_config()
            jax.block_until_ready(result)
            times.append(time.perf_counter() - start)

        avg_time = np.mean(times) * 1000
        print(f"Pipeline depth {pipe_depth}: {avg_time:.3f} ms")
        results[name] = avg_time

    print(f"\n{'='*50}")
    print("æµæ°´çº¿æ·±åº¦åˆ†æ:")
    print(f"{'='*50}")

    baseline = results["å½“å‰åŒç¼“å†²"]

    for name, time_ms in results.items():
        improvement = (baseline - time_ms) / baseline * 100
        print(f"{name:<12}: {time_ms:.3f} ms ({improvement:+.1f}%)")

    # æ‰¾åˆ°æœ€ä¼˜æ·±åº¦
    best_config = min(results.keys(), key=lambda x: results[x])
    best_time = results[best_config]

    print(f"\nğŸ¯ æœ€ä¼˜æµæ°´çº¿é…ç½®: {best_config}")
    print(f"æ€§èƒ½: {best_time:.3f} ms")
    print(f"ç›¸å¯¹åŸºå‡†æå‡: {(baseline - best_time) / baseline * 100:.1f}%")

    return results


def design_three_stage_pipeline():
    """è®¾è®¡ä¸‰é˜¶æ®µæµæ°´çº¿çš„å…·ä½“å®ç°å»ºè®®"""

    print("\n" + "=" * 60)
    print("ğŸš€ ä¸‰é˜¶æ®µæµæ°´çº¿è®¾è®¡å»ºè®®")
    print("=" * 60)

    print(
        """
é˜¶æ®µåˆ†è§£:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: DMA        â”‚ Stage 2: Preprocess â”‚ Stage 3: Compute â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ HBMâ†’VMEM transfer â”‚ â€¢ Data reshape      â”‚ â€¢ QK^T matmul      â”‚
â”‚ â€¢ Async copy K/V    â”‚ â€¢ Type conversion   â”‚ â€¢ Softmax          â”‚
â”‚ â€¢ Page indexing     â”‚ â€¢ Scaling (k_scale) â”‚ â€¢ Attention*V      â”‚
â”‚ â€¢ Buffer rotation   â”‚ â€¢ Memory layout opt â”‚ â€¢ Accumulation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ—¶åºé‡å :
Time:    T1      T2      T3      T4      T5
Stage1:  DMA_A   DMA_B   DMA_C   DMA_D   ...
Stage2:  Wait    Prep_A  Prep_B  Prep_C  ...
Stage3:  Wait    Wait    Comp_A  Comp_B  ...

ä¼˜åŠ¿:
âœ… DMAä¸è®¡ç®—çœŸæ­£å¹¶è¡Œ
âœ… å‡å°æ¯é˜¶æ®µçš„å·¥ä½œé‡
âœ… æ›´å¥½çš„å†…å­˜å±€éƒ¨æ€§
âœ… é™ä½åŒæ­¥å¼€é”€
"""
    )

    # ä¼°ç®—ç†è®ºæå‡
    print("ç†è®ºåˆ†æ:")
    print("- å½“å‰DMAå æ¯”: ~41.3%")
    print("- å¦‚æœDMAä¸è®¡ç®—å®Œå…¨é‡å : ç†è®ºæå‡ ~41%")
    print("- è€ƒè™‘é¢„å¤„ç†å¼€é”€: å®é™…æå‡ ~25-35%")
    print("- ä»0.687ms -> æœŸæœ›0.45-0.52ms")


if __name__ == "__main__":
    results = analyze_computation_breakdown()
    design_three_stage_pipeline()
