name: PR Test New

on:
  push:
    branches: [main, "epic/*"]
    paths:
      - "python/**"
      - "scripts/**"
      - "test/**"
      - ".github/workflows/pr-test.yml"
  pull_request:
    branches: [main, "epic/*"]
    paths:
      - "python/**"
      - "scripts/**"
      - "test/**"
      - ".github/workflows/pr-test.yml"

concurrency:
  group: pr-test-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # unit test
  unit-test-backend-1-tpu:
    if: github.event.pull_request.draft == false
    runs-on: tpuv6e-1
    strategy:
      fail-fast: false
      matrix:
        part: [0, 1, 2, 3]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        run: |
          uv venv --python 3.12
          source .venv/bin/activate
          uv pip install -e "python[all]"
          bash scripts/killall_sglang.sh

      - name: Run test
        timeout-minutes: 30
        run: |
          cd test/srt
          uv run python run_suite.py --suite per-commit-1-tpu \
            --auto-partition-id ${{ matrix.part }} \
            --auto-partition-size 4

  unit-test-backend-4-tpu:
    if: github.event.pull_request.draft == false
    runs-on: tpuv6e-4
    strategy:
      fail-fast: false
      matrix:
        part: [0, 1]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        run: |
          uv venv --python 3.12
          source .venv/bin/activate
          uv pip install -e "python[all]"
          bash scripts/killall_sglang.sh

      - name: Run test
        timeout-minutes: 30
        run: |
          cd test/srt
          uv run python run_suite.py --suite per-commit-4-tpu \
            --auto-partition-id ${{ matrix.part }} \
            --auto-partition-size 2

  # performence test
  performance-test-1-tpu:
    if: github.event.pull_request.draft == false
    runs-on: tpuv6e-1
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        run: |
          uv venv --python 3.12
          source .venv/bin/activate
          uv pip install -e "python[all]"
          bash scripts/killall_sglang.sh

      - name: Benchmark single req ttft on server
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_ttft_default

      - name: Benchmark single itl on server
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_itl_default

      - name: Benchmark 500 reqs input throughput
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_input_throughput_default

      - name: Benchmark 500 reqs output throughput
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_output_throughput_default

  performance-test-4-tpu:
    if: github.event.pull_request.draft == false
    needs: [unit-test-backend-4-tpu]
    runs-on: tpuv6e-4
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        run: |
          uv venv --python 3.12
          source .venv/bin/activate
          uv pip install -e "python[all]"
          bash scripts/killall_sglang.sh

      - name: Benchmark single req ttft on server (tp=4)
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_moe_ttft_default

      - name: Benchmark single itl on server (tp=4)
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_moe_itl_default

      - name: Benchmark 500 reqs input throughput (tp=4)
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_moe_input_throughput_default

      - name: Benchmark 500 reqs output throughput (tp=4)
        timeout-minutes: 10
        run: |
          cd test/srt
          python3 -m unittest test_bench_serving.TestBenchServing.test_moe_output_throughput_default

  # accuracy test
  accuracy-test-1-tpu:
    if: github.event.pull_request.draft == false
    runs-on: tpuv6e-1
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        run: |
          uv venv --python 3.12
          source .venv/bin/activate
          uv pip install -e "python[all]"
          bash scripts/killall_sglang.sh

      - name: Evaluate accuracy
        timeout-minutes: 20
        run: |
          cd test/srt
          uv run python -m unittest test_eval_accuracy_large.TestEvalAccuracyLarge.test_mmlu

  accuracy-test-4-tpu:
    if: github.event.pull_request.draft == false
    needs: [accuracy-test-1-tpu]
    runs-on: tpuv6e-4
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        run: |
          uv venv --python 3.12
          source .venv/bin/activate
          uv pip install -e "python[all]"
          bash scripts/killall_sglang.sh

      - name: Evaluate accuracy (TP=2)
        timeout-minutes: 20
        run: |
          cd test/srt
          uv run python -m unittest test_moe_eval_accuracy_large.TestMoEEvalAccuracyLarge.test_mmlu

  pr-test-finish:
    needs:
      [
        unit-test-backend-1-tpu,
        unit-test-backend-4-tpu,
        performance-test-1-tpu,
        performance-test-4-tpu,
        accuracy-test-1-tpu,
        accuracy-test-4-tpu,
      ]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Check all dependent job statuses
        run: |
          json_needs='${{ toJson(needs) }}'
          job_names=$(echo "$json_needs" | jq -r 'keys_unsorted[]')
          for job in $job_names; do
            result=$(echo "$json_needs" | jq -r --arg j "$job" '.[$j].result')
            echo "$job: $result"
            if [[ "$result" == "failure" || "$result" == "cancelled" ]]; then
              echo "Jobs failed"
              exit 1
            fi
          done
          echo "All jobs completed successfully"
